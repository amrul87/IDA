{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read txt data files and convert them to proper csv files\n",
    "# txtFile: input filename (including directory if applicable)\n",
    "# csvFile: output filename (including directory if applicable)\n",
    "# vtabchar: vertical tab character in the original file (to be replaced with newline command '\\n')\n",
    "# delim: delimiter character used in the original file (to be replaced with comma)\n",
    "def txt2csv(txtFile, csvFile, vtabchar, delim):\n",
    "    with open(txtFile, 'r') as file:\n",
    "        data = file.read().replace(vtabchar, '\\n').replace(delim, ',')\n",
    "    with open(csvFile, 'w') as file:\n",
    "        file.write(data)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filename and location for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original filename and directory for txt data files\n",
    "K1DI2_txt = './Data/Komponente/Komponente_K1DI2.txt'\n",
    "K2LE1_txt = './Data/Komponente/Komponente_K2LE1.txt' \n",
    "K2LE2_txt = './Data/Komponente/Komponente_K2LE2.txt'\n",
    "K2ST1_txt = './Data/Komponente/Komponente_K2ST1.txt'\n",
    "K3AG2_txt = './Data/Komponente/Komponente_K3AG2.txt'\n",
    "K7_txt    = './Data/Komponente/Komponente_K7.txt'\n",
    "\n",
    "# converted txt filename and directory\n",
    "K1DI2_csv = './Data/Komponente/Komponente_K1DI2.csv'\n",
    "K2LE1_csv = './Data/Komponente/Komponente_K2LE1.csv'\n",
    "K2LE2_csv = './Data/Komponente/Komponente_K2LE2.csv'\n",
    "K2ST1_csv = './Data/Komponente/Komponente_K2ST1.csv'\n",
    "K3AG2_csv = './Data/Komponente/Komponente_K3AG2.csv'\n",
    "K7_csv    = './Data/Komponente/Komponente_K7.csv'\n",
    "\n",
    "# original filename and directory for csv data files\n",
    "# component data files\n",
    "K1BE1_csv = './Data/Komponente/Komponente_K1BE1.csv'\n",
    "K1BE2_csv = './Data/Komponente/Komponente_K1BE2.csv'\n",
    "K1DI1_csv = './Data/Komponente/Komponente_K1DI1.csv'\n",
    "K2ST2_csv = './Data/Komponente/Komponente_K2ST2.csv'\n",
    "K3AG1_csv = './Data/Komponente/Komponente_K3AG1.csv'\n",
    "K3SG1_csv = './Data/Komponente/Komponente_K3SG1.csv'\n",
    "K3SG2_csv = './Data/Komponente/Komponente_K3SG2.csv'\n",
    "K4_csv    = './Data/Komponente/Komponente_K4.csv'\n",
    "K5_csv    = './Data/Komponente/Komponente_K5.csv'\n",
    "K6_csv    = './Data/Komponente/Komponente_K6.csv'    \n",
    "\n",
    "# vehicle data files\n",
    "bestFahr1_11_csv = './Data/Fahrzeug/Bestandteile_Fahrzeuge_OEM1_Typ11.csv'\n",
    "bestFahr1_12_csv = './Data/Fahrzeug/Bestandteile_Fahrzeuge_OEM1_Typ12.csv'\n",
    "bestFahr2_21_csv = './Data/Fahrzeug/Bestandteile_Fahrzeuge_OEM2_Typ21.csv'\n",
    "bestFahr2_22_csv = './Data/Fahrzeug/Bestandteile_Fahrzeuge_OEM2_Typ22.csv'\n",
    "\n",
    "fahr1_11_csv = './Data/Fahrzeug/Fahrzeuge_OEM1_Typ11.csv'\n",
    "fahr1_12_csv = './Data/Fahrzeug/Fahrzeuge_OEM1_Typ12.csv'\n",
    "fahr2_21_csv = './Data/Fahrzeug/Fahrzeuge_OEM2_Typ21.csv'\n",
    "fahr2_22_csv = './Data/Fahrzeug/Fahrzeuge_OEM2_Typ22.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and convert all the txt data files to csv\n",
    "txt2csv(K1DI2_txt, K1DI2_csv, '\t', '\\\\')\n",
    "txt2csv(K2LE1_txt, K2LE1_csv, '\u000b', 'II')\n",
    "txt2csv(K2LE2_txt, K2LE2_csv, '\u000b', '\\\\')\n",
    "txt2csv(K2ST1_txt, K2ST1_csv, '\u000b', '|')\n",
    "txt2csv(K3AG2_txt, K3AG2_csv, '\u000b', '\\\\')\n",
    "txt2csv(K7_txt   , K7_csv   , '\u000b', '\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data arrangements into 4 types, namely A, B, C, and D. \n",
    "# this separation is based on the column names of the datetime data type\n",
    "A = ['Fehlerhaft_Datum', 'origin']\n",
    "B = ['Produktionsdatum.x', 'Fehlerhaft_Datum.x', \n",
    "     'Produktionsdatum.y', 'Fehlerhaft_Datum.y']\n",
    "C = ['Produktionsdatum.x', 'Fehlerhaft_Datum.x', \n",
    "     'Produktionsdatum.y', 'Fehlerhaft_Datum.y', \n",
    "     'Produktionsdatum', 'Fehlerhaft_Datum']\n",
    "D = ['Produktionsdatum', 'Fehlerhaft_Datum']\n",
    "\n",
    "# set up a function to read the csv files\n",
    "def csvReader(csvFile, arr_type, delim=None):\n",
    "    if delim is not None:\n",
    "        dataset = pd.read_csv(csvFile, parse_dates=arr_type, \n",
    "                          low_memory=False, sep=delim)\n",
    "    else:\n",
    "        dataset = pd.read_csv(csvFile, parse_dates=arr_type, \n",
    "                          low_memory=False)\n",
    "    return dataset\n",
    "\n",
    "# read the converted csv files using the csvReader function\n",
    "K1DI2 = csvReader(K1DI2_csv, A)\n",
    "K2LE1 = csvReader(K2LE1_csv, B)\n",
    "K2LE2 = csvReader(K2LE2_csv, A)\n",
    "K2ST1 = csvReader(K2ST1_csv, D)\n",
    "K3AG2 = csvReader(K3AG2_csv, A)\n",
    "K7    = csvReader(K7_csv, A)\n",
    "\n",
    "# read the rest of the csv files using the csvReader function\n",
    "K1BE1 = csvReader(K1BE1_csv, A)\n",
    "K1BE2 = csvReader(K1BE2_csv, A, ';')\n",
    "K1DI1 = csvReader(K1DI1_csv, C)\n",
    "K2ST2 = csvReader(K2ST2_csv, A, ';')\n",
    "K3AG1 = csvReader(K3AG1_csv, C)\n",
    "K3SG1 = csvReader(K3SG1_csv, B)\n",
    "K3SG2 = csvReader(K3SG2_csv, A)\n",
    "K4    = csvReader(K4_csv,    B, ';')\n",
    "K5    = csvReader(K5_csv,    B)\n",
    "K6    = csvReader(K6_csv,    A, ';')\n",
    "\n",
    "# # read the vehicle data:\n",
    "# bestFahr1_11 = pd.read_csv(bestFahr1_11_csv)\n",
    "# bestFahr1_12 = pd.read_csv(bestFahr1_12_csv)\n",
    "# bestFahr2_21 = pd.read_csv(bestFahr2_21_csv, sep=';')\n",
    "# bestFahr2_22 = pd.read_csv(bestFahr2_22_csv, sep=';')\n",
    "# fahr1_11 = pd.read_csv(fahr1_11_csv, parse_dates=D, low_memory=False)\n",
    "# fahr1_12 = pd.read_csv(fahr1_12_csv, parse_dates=D, low_memory=False)\n",
    "# fahr2_21 = pd.read_csv(fahr2_21_csv, parse_dates=A, low_memory=False)\n",
    "# fahr2_22 = pd.read_csv(fahr2_22_csv, parse_dates=A, low_memory=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For datasets with data arrangements of type B and C, we need to consolidate the columns and eliminate the .x and .y suffixes. For type B, the tables are separated into 2, whereas for type C, the tables are separated into 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names to be renamed for type B\n",
    "col_names_x = {'Produktionsdatum.x':'Produktionsdatum', \n",
    "               'Herstellernummer.x':'Herstellernummer',\t\n",
    "               'Werksnummer.x':'Werksnummer',\n",
    "               'Fehlerhaft.x':'Fehlerhaft', \n",
    "               'Fehlerhaft_Datum.x':'Fehlerhaft_Datum',\n",
    "               'Fehlerhaft_Fahrleistung.x':'Fehlerhaft_Fahrleistung'}\n",
    "col_names_y = {'Produktionsdatum.y':'Produktionsdatum', \n",
    "               'Herstellernummer.y':'Herstellernummer',\t\n",
    "               'Werksnummer.y':'Werksnummer',\n",
    "               'Fehlerhaft.y':'Fehlerhaft', \n",
    "               'Fehlerhaft_Datum.y':'Fehlerhaft_Datum',\n",
    "               'Fehlerhaft_Fahrleistung.y':'Fehlerhaft_Fahrleistung'}\n",
    "\n",
    "# set up variables for the components. The components are engine (Motor), electrical components (Schaltung),\n",
    "# body components (Karosserie), and seats (Sitze)\n",
    "idMotor  = 'ID_Motor'        ; idSchalt  = 'ID_Schaltung'\n",
    "idMotorx = 'ID_Motor.x'      ; idSchaltx = 'ID_Schaltung.x'\n",
    "idMotory = 'ID_Motor.y'      ; idSchalty = 'ID_Schaltung.y'\n",
    "\n",
    "idKaros  = 'ID_Karosserie'   ; idSitze  = 'ID_Sitze'\n",
    "idKarosx = 'ID_Karosserie.x' ; idSitzex = 'ID_Sitze.x' \n",
    "idKarosy = 'ID_Karosserie.y' ; idSitzey = 'ID_Sitze.y'\n",
    "\n",
    "# separate type B tables based on the suffixes, rename the columns, and \n",
    "# concatenate vertically, and finally extract the columns that contain the data.\n",
    "# the cleaned up dataset is added with suffix '_c'\n",
    "def streamlineTypeB(dataset, colx, coly, ID, IDx, IDy):\n",
    "    dataset_x = dataset[dataset[IDx].notna()].rename(columns=colx)\n",
    "    dataset_y = dataset[dataset[IDy].notna()].rename(columns=coly)\n",
    "    dataset_x = dataset_x.rename(columns={IDx : ID})\n",
    "    dataset_y = dataset_y.rename(columns={IDy : ID})\n",
    "    dataset_x = dataset_x.loc[:, ID:'Fehlerhaft_Fahrleistung']\n",
    "    dataset_y = dataset_y.loc[:, ID:'Fehlerhaft_Fahrleistung']\n",
    "    dataset_c = pd.concat([dataset_x, dataset_y], axis=0).reset_index(drop=True)\n",
    "    dataset_c['Fehlerhaft'] = dataset_c['Fehlerhaft'].astype('bool')\n",
    "    return dataset_c\n",
    "\n",
    "K2LE1_c = streamlineTypeB(K2LE1, col_names_x, col_names_y, \n",
    "                            idSitze, idSitzex, idSitzey)\n",
    "K3SG1_c = streamlineTypeB(K3SG1, col_names_x, col_names_y, \n",
    "                            idSchalt, idSchaltx, idSchalty)\n",
    "K4_c    = streamlineTypeB(K4, col_names_x, col_names_y, \n",
    "                            idKaros, idKarosx, idKarosy)\n",
    "K5_c    = streamlineTypeB(K5, col_names_x, col_names_y, \n",
    "                            idKaros, idKarosx, idKarosy)\n",
    "\n",
    "# separate type C tables based on the suffixes, rename the columns, and \n",
    "# concatenate vertically, and finally extract the columns that contain the data.\n",
    "# the cleaned up dataset is added with suffix '_c'\n",
    "def streamlineTypeC(dataset, colx, coly, ID, IDx, IDy):\n",
    "    dataset_x = dataset[dataset[IDx].notna()].loc[:, IDx:'Fehlerhaft_Fahrleistung.x'].rename(columns=colx)\n",
    "    dataset_y = dataset[dataset[IDy].notna()].loc[:, IDy:'Fehlerhaft_Fahrleistung.y'].rename(columns=coly)\n",
    "    dataset_  = dataset[dataset[ID].notna()]\n",
    "    dataset_x = dataset_x.rename(columns={IDx : ID})\n",
    "    dataset_y = dataset_y.rename(columns={IDy : ID})\n",
    "    dataset_  = dataset_.loc[:, ID:'Fehlerhaft_Fahrleistung']    \n",
    "    dataset_c = pd.concat([dataset_x, dataset_y, dataset_], axis=0).reset_index(drop=True)\n",
    "    dataset_c['Fehlerhaft'] = dataset_c['Fehlerhaft'].astype('bool')\n",
    "    return dataset_c\n",
    "\n",
    "K1DI1_c = streamlineTypeC(K1DI1, col_names_x, col_names_y,\n",
    "                          idMotor, idMotorx, idMotory)\n",
    "K3AG1_c = streamlineTypeC(K3AG1, col_names_x, col_names_y,\n",
    "                          idSchalt, idSchaltx, idSchalty)\n",
    "K2ST1_c = K2ST1.loc[:, idSitze:'Fehlerhaft_Fahrleistung']\n",
    "K2ST1_c['Fehlerhaft'] = K2ST1_c['Fehlerhaft'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addProduktionsDatum(dataset):\n",
    "    dataset['Produktionsdatum'] = dataset['origin'] + pd.to_timedelta(dataset['Produktionsdatum_Origin_01011970'].astype('int'), unit='days')\n",
    "    return dataset\n",
    "\n",
    "def reformatDataset(dataset, ID):\n",
    "    dataset_c = pd.concat([dataset.loc[:,ID], \n",
    "                           dataset.loc[:,'Produktionsdatum'], \n",
    "                           dataset.loc[:,'Herstellernummer':'Fehlerhaft_Fahrleistung']], axis=1)\n",
    "    dataset_c['Fehlerhaft'] = dataset_c['Fehlerhaft'].astype('bool')\n",
    "    return dataset_c\n",
    "\n",
    "K1BE1_c = reformatDataset(addProduktionsDatum(K1BE1), idMotor)\n",
    "K1BE2_c = reformatDataset(addProduktionsDatum(K1BE2), idMotor)\n",
    "K1DI2_c = reformatDataset(addProduktionsDatum(K1DI2), idMotor)\n",
    "K2LE2_c = reformatDataset(addProduktionsDatum(K2LE2), idSitze)\n",
    "K2ST2_c = reformatDataset(addProduktionsDatum(K2ST2), idSitze)\n",
    "K3AG2_c = reformatDataset(addProduktionsDatum(K3AG2), idSchalt)\n",
    "K3SG2_c = reformatDataset(addProduktionsDatum(K3SG2), idSchalt)\n",
    "K6_c    = reformatDataset(addProduktionsDatum(K6), idKaros)\n",
    "K7_c    = reformatDataset(addProduktionsDatum(K7), idKaros)\n",
    "\n",
    "# classify the components into list based on the types of components (Motor, Sitze, Schaltung, and Karosserie)\n",
    "motorList      = [K1BE1_c, K1BE2_c, K1DI1_c, K1DI2_c]\n",
    "sitzeList      = [K2LE1_c, K2LE2_c, K2ST1_c, K2ST2_c]\n",
    "schaltungList  = [K3AG1_c, K3AG2_c, K3SG1_c, K3SG2_c]\n",
    "karosserieList = [K4_c, K5_c, K6_c, K7_c]\n",
    "\n",
    "motorName      = ['K1BE1', 'K1BE2', 'K1DI1', 'K1DI2']\n",
    "sitzeName      = ['K2LE1', 'K2LE2', 'K2ST1', 'K2ST2']\n",
    "schaltungName  = ['K3AG1', 'K3AG2', 'K3SG1', 'K3SG2']\n",
    "karosserieName = ['K4', 'K5', 'K6', 'K7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with all the datasets clean and proper, we can start doing the case analysis. In this case study, the components produced between January 1st, 2011 and December 31st, 2015 are considered. \n",
    "\n",
    "First, we filter out the components that is not produced within the considered time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will extract the dataset within the specified time period\n",
    "def timePeriodFilter(dataset, ID):\n",
    "    startDate = '2011-01-01'\n",
    "    endDate   = '2015-12-31'\n",
    "    dataset_2011until2015 = pd.concat([dataset[(dataset['Produktionsdatum'] >= startDate) & \n",
    "                                       (dataset['Produktionsdatum'] <= endDate)].loc[:,[ID,'Produktionsdatum']],\n",
    "                                       dataset[(dataset['Produktionsdatum'] >= startDate) & \n",
    "                                       (dataset['Produktionsdatum'] <= endDate)].loc[:,'Herstellernummer':'Fehlerhaft_Fahrleistung']],\n",
    "                                       axis=1).reset_index(drop=True)\n",
    "    return dataset_2011until2015\n",
    "\n",
    "# the function below will slice all the components dataset to the specified time range\n",
    "def component_2011until2015(datasetList, ID):\n",
    "    datasetlist_2011until2015 = []\n",
    "    for dataset in datasetList:\n",
    "        datasetlist_2011until2015.append(timePeriodFilter(dataset, ID))\n",
    "    return datasetlist_2011until2015\n",
    "\n",
    "motorList_2011until2015      = component_2011until2015(motorList, idMotor)\n",
    "sitzeList_2011until2015      = component_2011until2015(sitzeList, idSitze)\n",
    "schaltungList_2011until2015  = component_2011until2015(schaltungList, idSchalt)\n",
    "karosserieList_2011until2015 = component_2011until2015(karosserieList, idKaros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to calculate the relative frequency of defective components: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a function to calculate relative frequency\n",
    "def calcRelFreq(dataset, ID, productionYear):\n",
    "    relFreq = []\n",
    "    for year in productionYear:\n",
    "        numDefect = dataset[(dataset['Fehlerhaft'] == True) &\n",
    "                            (dataset['Produktionsdatum'].dt.year == year)].loc[:,'Fehlerhaft'].count()\n",
    "        numKompon = dataset[ID].count()\n",
    "        relFreq.append(numDefect/numKompon)\n",
    "    return relFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare lists of components that will be use to store the annual relative frequencies of the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the production year\n",
    "productionYear = [2011, 2012, 2013, 2014, 2015]\n",
    "productionYear_dict = {'ProductionYear':productionYear}\n",
    "\n",
    "# create a function that will be used to calculate annual relative frequency\n",
    "# of components in the components list\n",
    "def component_relFrq(datasetlist, ID, prodYear):\n",
    "    datasetlist_relFrq = []\n",
    "    for dataset in datasetlist:\n",
    "        datasetlist_relFrq.append(calcRelFreq(dataset, ID, prodYear))\n",
    "    return datasetlist_relFrq\n",
    "\n",
    "motorList_relFrq      = component_relFrq(motorList_2011until2015, idMotor, productionYear)\n",
    "sitzeList_relFrq      = component_relFrq(sitzeList_2011until2015, idSitze, productionYear)\n",
    "schaltungList_relFrq  = component_relFrq(schaltungList_2011until2015, idSchalt, productionYear)\n",
    "karosserieList_relFrq = component_relFrq(karosserieList_2011until2015, idKaros, productionYear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframes of the relative frequency for all the components produced between January 1st, 2011 and December 31st, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the production year\n",
    "productionYearDF = pd.DataFrame(productionYear_dict)\n",
    "# create a function to create a list of dataframes of the components' failure \n",
    "# relative frequency\n",
    "def createDataFrame(datasetList_relFrq, componentName):\n",
    "    relFreqDataframe = []\n",
    "    for i in range(len(datasetList_relFrq)):\n",
    "        relFreqDataframe.append(pd.DataFrame(datasetList_relFrq[i], columns=[componentName[i]]))\n",
    "    return relFreqDataframe\n",
    "\n",
    "motorList_relFrqDataframe      = createDataFrame(motorList_relFrq, motorName)\n",
    "sitzeList_relFrqDataframe      = createDataFrame(sitzeList_relFrq, sitzeName)\n",
    "schaltungList_relFrqDataframe  = createDataFrame(schaltungList_relFrq, schaltungName)\n",
    "karosserieList_relFrqDataframe = createDataFrame(karosserieList_relFrq, karosserieName)\n",
    "\n",
    "# combine dataframes in the list into a single dataframe for each component type\n",
    "def combineDF(datasetList_relFrqDataframe):\n",
    "    for i in range(1, len(datasetList_relFrqDataframe)):\n",
    "        datasetListRelFrqDataframe = datasetList_relFrqDataframe[0].join(datasetList_relFrqDataframe[i])\n",
    "        datasetList_relFrqDataframe[0] = datasetListRelFrqDataframe\n",
    "    datasetListRelFrqDataframe = pd.concat([productionYearDF, datasetListRelFrqDataframe], axis=1)\n",
    "    datasetListRelFrqDataframe.set_index('ProductionYear')\n",
    "    return datasetListRelFrqDataframe\n",
    "\n",
    "motorListRelFrqDataframe = combineDF(motorList_relFrqDataframe)\n",
    "sitzeListRelFrqDataframe = combineDF(sitzeList_relFrqDataframe)\n",
    "schaltungListRelFrqDataframe = combineDF(schaltungList_relFrqDataframe)\n",
    "karosserieListRelFrqDataframe = combineDF(karosserieList_relFrqDataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductionYear     K3AG1     K3AG2     K3SG1     K3SG2\n",
      "0            2011  0.026125  0.199476  0.020028  0.019780\n",
      "1            2012  0.026346  0.199934  0.019802  0.019768\n",
      "2            2013  0.026185  0.200733  0.019924  0.020263\n",
      "3            2014  0.025597  0.198726  0.019811  0.019968\n",
      "4            2015  0.025965  0.201132  0.019836  0.019892\n"
     ]
    }
   ],
   "source": [
    "print(schaltungListRelFrqDataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K1BE1</th>\n",
       "      <th>K1BE2</th>\n",
       "      <th>K1DI1</th>\n",
       "      <th>K1DI2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035340</td>\n",
       "      <td>0.035017</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>0.199849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034945</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.200859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035494</td>\n",
       "      <td>0.034767</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.200161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035179</td>\n",
       "      <td>0.035368</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.200481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.198650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      K1BE1     K1BE2     K1DI1     K1DI2\n",
       "0  0.035340  0.035017  0.020137  0.199849\n",
       "1  0.034945  0.035415  0.020174  0.200859\n",
       "2  0.035494  0.034767  0.019725  0.200161\n",
       "3  0.035179  0.035368  0.020169  0.200481\n",
       "4  0.034858  0.034974  0.020077  0.198650"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorListRelFrqDataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
